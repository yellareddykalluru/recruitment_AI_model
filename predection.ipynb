{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Randomly sample 5000 rows\n",
    "data = df.sample(n=3000, random_state=42)\n",
    "\n",
    "# Save the reduced dataset\n",
    "data.to_csv(\"reduced_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Count words in each row of the 'transcript' column\n",
    "data[\"no-words-Resume\"] = data[\"Resume\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Save the updated dataset (optional)\n",
    "data.to_csv(\"updated_dataset.csv\", index=False)\n",
    "\n",
    "# Display the first few r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to count characters in a text\n",
    "def count_characters(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return 0\n",
    "    return len(str(text))  # Convert to string and count characters\n",
    "\n",
    "# Apply the function to the 'transcript' column\n",
    "data[\"char_count_trans\"] = data[\"Transcript\"].apply(count_characters)\n",
    "\n",
    "# Display the first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset if needed\n",
    "data.to_csv(\"dataset_with_char_count.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to count characters in a text\n",
    "def count_characters(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return 0\n",
    "    return len(str(text))  # Convert to string and count characters\n",
    "\n",
    "# Apply the function to the 'transcript' column\n",
    "data[\"char_count_Resume\"] = data[\"Resume\"].apply(count_characters)\n",
    "\n",
    "# Display the first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset if needed\n",
    "data.to_csv(\"dataset_with_char_count.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\yella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to compute sentiment using VADER\n",
    "def get_vader_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return sia.polarity_scores(str(text))[\"compound\"]  # Returns a sentiment score\n",
    "\n",
    "data[\"sentiment_score_trans\"] = data[\"Transcript\"].apply(get_vader_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\yella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to compute sentiment using VADER\n",
    "def get_vader_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return sia.polarity_scores(str(text))[\"compound\"]  # Returns a sentiment score\n",
    "\n",
    "data[\"sentiment_score_Resume\"] = data[\"Resume\"].apply(get_vader_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Count words in each row of the 'transcript' column\n",
    "data[\"no-words-trans\"] = data[\"Transcript\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Save the updated dataset (optional)\n",
    "data.to_csv(\"updated_dataset.csv\", index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "role_transcript_similarity = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    Role = str(data['Role'][i])  # Convert to string to avoid errors\n",
    "    Transcript = str(data['Transcript'][i])\n",
    "    \n",
    "    # Compute TF-IDF and cosine similarity\n",
    "    similarity = cosine_similarity(vectorizer.fit_transform([Role, Transcript]))[0, 1]\n",
    "    \n",
    "    role_transcript_similarity.append(similarity)\n",
    "\n",
    "data['role_transcript_similarity'] = role_transcript_similarity\n",
    "\n",
    "# Display first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset\n",
    "data.to_csv(\"dataset_with_cosine_similarity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "role_Resume_similarity = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    Role = str(data['Role'][i])  # Convert to string to avoid errors\n",
    "    Resume = str(data['Resume'][i])\n",
    "    \n",
    "    # Compute TF-IDF and cosine similarity\n",
    "    similarity = cosine_similarity(vectorizer.fit_transform([Role, Resume]))[0, 1]\n",
    "    \n",
    "    role_Resume_similarity.append(similarity)\n",
    "\n",
    "data['role_Resume_similarity'] = role_Resume_similarity\n",
    "\n",
    "# Display first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset\n",
    "data.to_csv(\"dataset_with_cosine_similarity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "Job_Description_Resume_similarity = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    Job_Description = str(data['Job_Description'][i])  # Convert to string to avoid errors\n",
    "    Resume = str(data['Resume'][i])\n",
    "    \n",
    "    # Compute TF-IDF and cosine similarity\n",
    "    similarity = cosine_similarity(vectorizer.fit_transform([Job_Description, Resume]))[0, 1]\n",
    "    \n",
    "    Job_Description_Resume_similarity.append(similarity)\n",
    "\n",
    "data['Job_Description_Resume_similarity'] = Job_Description_Resume_similarity\n",
    "\n",
    "# Display first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset\n",
    "data.to_csv(\"dataset_with_cosine_similarity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "Job_Description_Transcript_similarity = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    Job_Description = str(data['Job_Description'][i])  # Convert to string to avoid errors\n",
    "    Transcript = str(data['Transcript'][i])\n",
    "    \n",
    "    # Compute TF-IDF and cosine similarity\n",
    "    similarity = cosine_similarity(vectorizer.fit_transform([Job_Description, Transcript]))[0, 1]\n",
    "    \n",
    "    Job_Description_Transcript_similarity.append(similarity)\n",
    "\n",
    "data['Job_Description_Transcript_similarity'] = Job_Description_Transcript_similarity\n",
    "\n",
    "# Display first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset\n",
    "data.to_csv(\"dataset_with_cosine_similarity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "Resume_transcript_similarity = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    Resume = str(data['Resume'][i])  # Convert to string to avoid errors\n",
    "    Transcript = str(data['Transcript'][i])\n",
    "    \n",
    "    # Compute TF-IDF and cosine similarity\n",
    "    similarity = cosine_similarity(vectorizer.fit_transform([Resume, Transcript]))[0, 1]\n",
    "    \n",
    "    Resume_transcript_similarity.append(similarity)\n",
    "\n",
    "data['Resume_transcript_similarity'] = Resume_transcript_similarity\n",
    "\n",
    "# Display first few rows\n",
    "\n",
    "\n",
    "# Save the modified dataset\n",
    "data.to_csv(\"dataset_with_cosine_similarity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return torch.zeros(768).tolist()  # Return zero vector of size 768\n",
    "    \n",
    "    tokens = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():  # No gradient computation for inference\n",
    "        output = model(**tokens)\n",
    "    \n",
    "    embedding = output.last_hidden_state[:, 0, :].squeeze().tolist()  # Extract [CLS] token embedding\n",
    "    return embedding\n",
    "\n",
    "# Apply function to 'Transcript' column\n",
    "data[\"bert_embedding_trans\"] = data[\"Transcript\"].apply(get_bert_embedding)\n",
    "\n",
    "# Save dataset (Note: BERT embeddings are lists, so saving as JSON might be better)\n",
    "data.to_csv(\"dataset_with_bert_embedding.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Resume</th>\n",
       "      <th>decision</th>\n",
       "      <th>Reason_for_decision</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>no-words-Resume</th>\n",
       "      <th>char_count_trans</th>\n",
       "      <th>char_count_Resume</th>\n",
       "      <th>sentiment_score_trans</th>\n",
       "      <th>sentiment_score_Resume</th>\n",
       "      <th>no-words-trans</th>\n",
       "      <th>role_transcript_similarity</th>\n",
       "      <th>Resume_transcript_similarity</th>\n",
       "      <th>role_Resume_similarity</th>\n",
       "      <th>Job_Description_Resume_similarity</th>\n",
       "      <th>Job_Description_Transcript_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jasojo159</td>\n",
       "      <td>Jason Jones</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Interviewer: Good morning, Jason. It's great t...</td>\n",
       "      <td>Here's a professional resume for Jason Jones:\\...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lacked leadership skills for a senior position.</td>\n",
       "      <td>Be part of a passionate team at the forefront ...</td>\n",
       "      <td>342</td>\n",
       "      <td>3778</td>\n",
       "      <td>2613</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>606</td>\n",
       "      <td>0.055917</td>\n",
       "      <td>0.408546</td>\n",
       "      <td>0.173593</td>\n",
       "      <td>0.115580</td>\n",
       "      <td>0.090878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annma759</td>\n",
       "      <td>Ann Marshall</td>\n",
       "      <td>Game Developer</td>\n",
       "      <td>Interview Scene\\n\\nA conference room with a ta...</td>\n",
       "      <td>Here's a professional resume for Ann Marshall:...</td>\n",
       "      <td>select</td>\n",
       "      <td>Strong technical skills in AI and ML.</td>\n",
       "      <td>Help us build the next-generation products as ...</td>\n",
       "      <td>51</td>\n",
       "      <td>3862</td>\n",
       "      <td>429</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.7841</td>\n",
       "      <td>635</td>\n",
       "      <td>0.050310</td>\n",
       "      <td>0.215035</td>\n",
       "      <td>0.136352</td>\n",
       "      <td>0.083954</td>\n",
       "      <td>0.182354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patrmc729</td>\n",
       "      <td>Patrick Mcclain</td>\n",
       "      <td>Human Resources Specialist</td>\n",
       "      <td>Interview Setting: A conference room in a medi...</td>\n",
       "      <td>Here's a professional resume for Patrick Mccla...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Insufficient system design expertise for senio...</td>\n",
       "      <td>We need a Human Resources Specialist to enhanc...</td>\n",
       "      <td>405</td>\n",
       "      <td>4525</td>\n",
       "      <td>3046</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>739</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.488654</td>\n",
       "      <td>0.124657</td>\n",
       "      <td>0.207421</td>\n",
       "      <td>0.224480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patrgr422</td>\n",
       "      <td>Patricia Gray</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Here's a simulated professional interview for ...</td>\n",
       "      <td>Here's a professional resume for Patricia Gray...</td>\n",
       "      <td>select</td>\n",
       "      <td>Impressive leadership and communication abilit...</td>\n",
       "      <td>Be part of a passionate team at the forefront ...</td>\n",
       "      <td>319</td>\n",
       "      <td>5360</td>\n",
       "      <td>2344</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>843</td>\n",
       "      <td>0.073634</td>\n",
       "      <td>0.430758</td>\n",
       "      <td>0.129278</td>\n",
       "      <td>0.095908</td>\n",
       "      <td>0.130067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amangr696</td>\n",
       "      <td>Amanda Gross</td>\n",
       "      <td>E-commerce Specialist</td>\n",
       "      <td>Here's the simulated interview:\\n\\nInterviewer...</td>\n",
       "      <td>Here's a professional resume for Amanda Gross:...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lacked leadership skills for a senior position.</td>\n",
       "      <td>We are looking for an experienced E-commerce S...</td>\n",
       "      <td>357</td>\n",
       "      <td>3733</td>\n",
       "      <td>2784</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>585</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>0.372419</td>\n",
       "      <td>0.061090</td>\n",
       "      <td>0.169097</td>\n",
       "      <td>0.246319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10169</th>\n",
       "      <td>uppaup496</td>\n",
       "      <td>Diana Miller</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Here's a simulated interview for a Product Man...</td>\n",
       "      <td>Here's a sample resume for Diana Miller:\\n\\n**...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Unsatisfactory references or background check.</td>\n",
       "      <td>Here is a comprehensive job description for a ...</td>\n",
       "      <td>406</td>\n",
       "      <td>3213</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>543</td>\n",
       "      <td>0.098668</td>\n",
       "      <td>0.342394</td>\n",
       "      <td>0.281772</td>\n",
       "      <td>0.566751</td>\n",
       "      <td>0.359923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10170</th>\n",
       "      <td>uppaup497</td>\n",
       "      <td>Grace Taylor</td>\n",
       "      <td>UI Engineer</td>\n",
       "      <td>**Interviewer:** Hi Grace, thank you for comin...</td>\n",
       "      <td>Here's a sample resume for Grace Taylor:\\n\\n**...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lack of relevant skills or experience.</td>\n",
       "      <td>Here is a sample job description for a UI Engi...</td>\n",
       "      <td>454</td>\n",
       "      <td>3355</td>\n",
       "      <td>3137</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>568</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>0.323516</td>\n",
       "      <td>0.196570</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>0.310997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10171</th>\n",
       "      <td>uppaup498</td>\n",
       "      <td>Hank Brown</td>\n",
       "      <td>UI Engineer</td>\n",
       "      <td>Here's a simulated interview for a UI Engineer...</td>\n",
       "      <td>Here's a sample resume for Hank Brown:\\n\\n**Ha...</td>\n",
       "      <td>select</td>\n",
       "      <td>Growth mindset and adaptability.</td>\n",
       "      <td>Here is a job description for a UI Engineer ro...</td>\n",
       "      <td>414</td>\n",
       "      <td>5643</td>\n",
       "      <td>3201</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>939</td>\n",
       "      <td>0.118025</td>\n",
       "      <td>0.460503</td>\n",
       "      <td>0.182907</td>\n",
       "      <td>0.562924</td>\n",
       "      <td>0.656624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>uppaup499</td>\n",
       "      <td>Diana Wilson</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Here's a simulated interview for a Data Engine...</td>\n",
       "      <td>Here's a sample resume for Diana Wilson:\\n\\n**...</td>\n",
       "      <td>reject</td>\n",
       "      <td>Lack of relevant skills or experience.</td>\n",
       "      <td>Here is a comprehensive job description for a ...</td>\n",
       "      <td>406</td>\n",
       "      <td>3227</td>\n",
       "      <td>2997</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>515</td>\n",
       "      <td>0.279136</td>\n",
       "      <td>0.458663</td>\n",
       "      <td>0.359214</td>\n",
       "      <td>0.701930</td>\n",
       "      <td>0.584231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>uppaup500</td>\n",
       "      <td>Charlie Miller</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Here's a simulated interview for a Product Man...</td>\n",
       "      <td>Here's a sample resume for Charlie Miller, a P...</td>\n",
       "      <td>select</td>\n",
       "      <td>Strong cultural fit.</td>\n",
       "      <td>Here is a comprehensive job description for a ...</td>\n",
       "      <td>392</td>\n",
       "      <td>5347</td>\n",
       "      <td>2941</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>810</td>\n",
       "      <td>0.173467</td>\n",
       "      <td>0.588241</td>\n",
       "      <td>0.295233</td>\n",
       "      <td>0.706727</td>\n",
       "      <td>0.678253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10174 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID             Name                        Role  \\\n",
       "0      jasojo159      Jason Jones       E-commerce Specialist   \n",
       "1       annma759     Ann Marshall              Game Developer   \n",
       "2      patrmc729  Patrick Mcclain  Human Resources Specialist   \n",
       "3      patrgr422    Patricia Gray       E-commerce Specialist   \n",
       "4      amangr696     Amanda Gross       E-commerce Specialist   \n",
       "...          ...              ...                         ...   \n",
       "10169  uppaup496     Diana Miller             Product Manager   \n",
       "10170  uppaup497     Grace Taylor                 UI Engineer   \n",
       "10171  uppaup498       Hank Brown                 UI Engineer   \n",
       "10172  uppaup499     Diana Wilson               Data Engineer   \n",
       "10173  uppaup500   Charlie Miller             Product Manager   \n",
       "\n",
       "                                              Transcript  \\\n",
       "0      Interviewer: Good morning, Jason. It's great t...   \n",
       "1      Interview Scene\\n\\nA conference room with a ta...   \n",
       "2      Interview Setting: A conference room in a medi...   \n",
       "3      Here's a simulated professional interview for ...   \n",
       "4      Here's the simulated interview:\\n\\nInterviewer...   \n",
       "...                                                  ...   \n",
       "10169  Here's a simulated interview for a Product Man...   \n",
       "10170  **Interviewer:** Hi Grace, thank you for comin...   \n",
       "10171  Here's a simulated interview for a UI Engineer...   \n",
       "10172  Here's a simulated interview for a Data Engine...   \n",
       "10173  Here's a simulated interview for a Product Man...   \n",
       "\n",
       "                                                  Resume decision  \\\n",
       "0      Here's a professional resume for Jason Jones:\\...   reject   \n",
       "1      Here's a professional resume for Ann Marshall:...   select   \n",
       "2      Here's a professional resume for Patrick Mccla...   reject   \n",
       "3      Here's a professional resume for Patricia Gray...   select   \n",
       "4      Here's a professional resume for Amanda Gross:...   reject   \n",
       "...                                                  ...      ...   \n",
       "10169  Here's a sample resume for Diana Miller:\\n\\n**...   reject   \n",
       "10170  Here's a sample resume for Grace Taylor:\\n\\n**...   reject   \n",
       "10171  Here's a sample resume for Hank Brown:\\n\\n**Ha...   select   \n",
       "10172  Here's a sample resume for Diana Wilson:\\n\\n**...   reject   \n",
       "10173  Here's a sample resume for Charlie Miller, a P...   select   \n",
       "\n",
       "                                     Reason_for_decision  \\\n",
       "0        Lacked leadership skills for a senior position.   \n",
       "1                  Strong technical skills in AI and ML.   \n",
       "2      Insufficient system design expertise for senio...   \n",
       "3      Impressive leadership and communication abilit...   \n",
       "4        Lacked leadership skills for a senior position.   \n",
       "...                                                  ...   \n",
       "10169     Unsatisfactory references or background check.   \n",
       "10170             Lack of relevant skills or experience.   \n",
       "10171                   Growth mindset and adaptability.   \n",
       "10172             Lack of relevant skills or experience.   \n",
       "10173                               Strong cultural fit.   \n",
       "\n",
       "                                         Job_Description  no-words-Resume  \\\n",
       "0      Be part of a passionate team at the forefront ...              342   \n",
       "1      Help us build the next-generation products as ...               51   \n",
       "2      We need a Human Resources Specialist to enhanc...              405   \n",
       "3      Be part of a passionate team at the forefront ...              319   \n",
       "4      We are looking for an experienced E-commerce S...              357   \n",
       "...                                                  ...              ...   \n",
       "10169  Here is a comprehensive job description for a ...              406   \n",
       "10170  Here is a sample job description for a UI Engi...              454   \n",
       "10171  Here is a job description for a UI Engineer ro...              414   \n",
       "10172  Here is a comprehensive job description for a ...              406   \n",
       "10173  Here is a comprehensive job description for a ...              392   \n",
       "\n",
       "       char_count_trans  char_count_Resume  sentiment_score_trans  \\\n",
       "0                  3778               2613                 0.9993   \n",
       "1                  3862                429                 0.9992   \n",
       "2                  4525               3046                 0.9987   \n",
       "3                  5360               2344                 0.9994   \n",
       "4                  3733               2784                 0.9976   \n",
       "...                 ...                ...                    ...   \n",
       "10169              3213               3128                 0.9932   \n",
       "10170              3355               3137                 0.9985   \n",
       "10171              5643               3201                 0.9996   \n",
       "10172              3227               2997                 0.9966   \n",
       "10173              5347               2941                 0.9990   \n",
       "\n",
       "       sentiment_score_Resume  no-words-trans  role_transcript_similarity  \\\n",
       "0                      0.9958             606                    0.055917   \n",
       "1                      0.7841             635                    0.050310   \n",
       "2                      0.9969             739                    0.016621   \n",
       "3                      0.9969             843                    0.073634   \n",
       "4                      0.9919             585                    0.049585   \n",
       "...                       ...             ...                         ...   \n",
       "10169                  0.9973             543                    0.098668   \n",
       "10170                  0.9913             568                    0.031816   \n",
       "10171                  0.9955             939                    0.118025   \n",
       "10172                  0.9796             515                    0.279136   \n",
       "10173                  0.9892             810                    0.173467   \n",
       "\n",
       "       Resume_transcript_similarity  role_Resume_similarity  \\\n",
       "0                          0.408546                0.173593   \n",
       "1                          0.215035                0.136352   \n",
       "2                          0.488654                0.124657   \n",
       "3                          0.430758                0.129278   \n",
       "4                          0.372419                0.061090   \n",
       "...                             ...                     ...   \n",
       "10169                      0.342394                0.281772   \n",
       "10170                      0.323516                0.196570   \n",
       "10171                      0.460503                0.182907   \n",
       "10172                      0.458663                0.359214   \n",
       "10173                      0.588241                0.295233   \n",
       "\n",
       "       Job_Description_Resume_similarity  \\\n",
       "0                               0.115580   \n",
       "1                               0.083954   \n",
       "2                               0.207421   \n",
       "3                               0.095908   \n",
       "4                               0.169097   \n",
       "...                                  ...   \n",
       "10169                           0.566751   \n",
       "10170                           0.700052   \n",
       "10171                           0.562924   \n",
       "10172                           0.701930   \n",
       "10173                           0.706727   \n",
       "\n",
       "       Job_Description_Transcript_similarity  \n",
       "0                                   0.090878  \n",
       "1                                   0.182354  \n",
       "2                                   0.224480  \n",
       "3                                   0.130067  \n",
       "4                                   0.246319  \n",
       "...                                      ...  \n",
       "10169                               0.359923  \n",
       "10170                               0.310997  \n",
       "10171                               0.656624  \n",
       "10172                               0.584231  \n",
       "10173                               0.678253  \n",
       "\n",
       "[10174 rows x 19 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
